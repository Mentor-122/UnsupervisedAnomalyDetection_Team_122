# -*- coding: utf-8 -*-
"""Milestone2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X0SGq2gP9Qnvtc2MeNvYVmZvxaPe3VqM

**MileStone2**

**Name-** **Om Late**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
data = pd.read_csv("/content/Health1.csv")
data.head()

# original data
data.info()

irrelevant_columns=['Entity Type of the Provider',
 'Street Address 1 of the Provider',
'Street Address 2 of the Provider',
'Zip Code of the Provider',
'Medicare Participation Indicator',
'Place of Service',
'HCPCS Code',
'HCPCS Description',
'HCPCS Drug Indicator',
'Country Code of the Provider']
data=data.drop(columns=irrelevant_columns)

data.head()

# Merging the name columns into a single column
data['Full Name'] = data['First Name of the Provider'].fillna('') + ' ' + \
 data['Middle Initial of the Provider'].fillna('') + ' ' + \
 data['Last Name/Organization Name of the Provider'].fillna('')
data['Full Name'] = data['Full Name'].str.strip()
data = data.drop(columns=['Last Name/Organization Name of the Provider',
 'First Name of the Provider',
'Middle Initial of the Provider'])
full_name_column = data.pop('Full Name')
data.insert(1, 'Full Name', full_name_column)
data.head()

# Uniform format of credentials
data['Credentials of the Provider'] = data['Credentials of the Provider'].str.replace(r'\.', '', regex=True).str.upper()
data.head()

"""# **Converting Object to Numeric**"""

numeric_columns = [
 'Number of Services',
 'Number of Medicare Beneficiaries',
 'Number of Distinct Medicare Beneficiary/Per Day Services',
 'Average Medicare Allowed Amount',
 'Average Submitted Charge Amount',
 'Average Medicare Payment Amount',
 'Average Medicare Standardized Amount'
]
for column in numeric_columns:
 data[column] = pd.to_numeric(data[column], errors='coerce')


data.info()

# missing values
print(data.isnull().sum())

# Imputation of numeric missing values with mean
data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())
print(data.isnull().sum())

categorical_columns = ['Credentials of the Provider',
                        'Gender of the Provider',
                        'City of the Provider',
                        'State Code of the Provider']
for column in categorical_columns:
    data[column].fillna(data[column].mode()[0], inplace=True)
print(data.isnull().sum())

# Check for duplicates
print(data.duplicated().sum())

data.head()

def frequency_encode(df, columns):
  for column in columns:
    freq_encoding = df[column].value_counts() / len(df)
    new_column_name = column + '_Freq'
    # Check if column exists before inserting
    if new_column_name not in df.columns:
        df.insert(df.columns.get_loc(column) + 1, new_column_name, df[column].map(freq_encoding))
  return df
columns_to_encode=[ 'Credentials of the Provider',
                    'Gender of the Provider',
                    'Provider Type',
                    'State Code of the Provider']
data = frequency_encode(data, columns_to_encode)
data.head()

#Performing Standardization on Numerical Columns
from sklearn.preprocessing import StandardScaler
standardization_columns=['Number of Services',
                         'Number of Medicare Beneficiaries',
                         'Number of Distinct Medicare Beneficiary/Per Day Services',
                         'Average Medicare Allowed Amount',
                         'Average Submitted Charge Amount',
                         'Average Medicare Payment Amount',
                         'Average Medicare Standardized Amount',
                         'Credentials of the Provider_Freq',
                         'Gender of the Provider_Freq',
                         'State Code of the Provider_Freq' ]
# Standardization
standard_scaler = StandardScaler()
data[standardization_columns] = standard_scaler.fit_transform(data[standardization_columns])
data_copy=data.copy()
print("Standardized DataFrame:")
data.head()

#Dimensionality Reduction using PCA
from sklearn.decomposition import PCA
df=data.copy()
# Imputation of categorical columns with mode
categorical_columns = ['Full Name',
                        'Credentials of the Provider',
                        'Gender of the Provider',
                        'City of the Provider',
                        'Provider Type',
                        'State Code of the Provider']
for column in df.columns:
 df[column].fillna(df[column].mode()[0], inplace=True)
df = df.drop(columns=categorical_columns)
pca = PCA(n_components=2)
pca_result = pca.fit_transform(df)
# DataFrame of PCA results
pca_df = pd.DataFrame(pca_result, columns=['PCA1', 'PCA2'])
# Scatter plot of PCA1 and PCA2
plt.figure(figsize=(8, 6))
plt.scatter(pca_df['PCA1'], pca_df['PCA2'])
plt.xlabel('PCA1')
plt.ylabel('PCA2')
plt.title('PCA of Transformed Data')
plt.grid(True)
plt.show()

# Plot PCA1 as a histogram
plt.hist(pca_df['PCA1'], bins=20, edgecolor='black')
plt.xlabel('PCA1 Values')
plt.ylabel('Frequency')
plt.title('Histogram of PCA1 Values')
plt.grid(True)
plt.show()

# Plot PCA2 as a histogram
plt.hist(pca_df['PCA2'], bins=20, edgecolor='black')
plt.xlabel('PCA2 Values')
plt.ylabel('Frequency')
plt.title('Histogram of PCA2 Values')
plt.grid(True)
plt.show()

#CLUSTERING
#K MEANS CLUSTERING
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score
kmeans = KMeans(n_clusters=2, random_state=42)
data['Cluster_KMeans'] = kmeans.fit_predict(data[numeric_columns])
sns.scatterplot(data=data, x='Number of Medicare Beneficiaries', y='Average Submitted Charge Amount',
 hue='Cluster_KMeans', palette='viridis', legend='full')
plt.title('K-Means Clustering')
plt.show()

# Clustering using K-Means
kmeans = KMeans(n_clusters=3, random_state=42)
data['Cluster_KMeans'] = kmeans.fit_predict(data[numeric_columns])
sns.scatterplot(data=data, x='Number of Services', y='Average Medicare Payment Amount', hue='Cluster_KMeans',
 palette='viridis', legend='full')
plt.title('K-Means Clustering')
plt.show()

#Algoplot of K-Means
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
k = 5
fig, axes = plt.subplots(4, 2, figsize=(14, 18))
fig.subplots_adjust(hspace=0.4, wspace=0.4)
axes = axes.flatten()
for i, col in enumerate(numeric_columns):
    # Perform K-Means clustering on the current column
    kmeans = KMeans(n_clusters=k, random_state=0)
    data['Cluster'] = kmeans.fit_predict(data[[col]])
    # Plot the column against its K-Means cluster assignments
    ax = axes[i]
    ax.scatter(data.index, data[col], c=data['Cluster'], s=50, alpha=0.5)
    ax.set_title(f'{col} - K-Means Clustering')
    ax.set_xlabel('Index')
    ax.set_ylabel(col)
    ax.set_xticks([])
if i < len(numeric_columns) - 2:
  ax.set_xticklabels([])
for j in range(i + 1, len(axes)):
  fig.delaxes(axes[j])
plt.tight_layout()
plt.show()

#DB SCAN CLUSTERING
from sklearn.cluster import DBSCAN
# Clustering using DBSCAN
dbscan = DBSCAN(eps=0.7, min_samples=6)
data['Cluster_DBSCAN'] = dbscan.fit_predict(data[numeric_columns])
# Number of noise points
num_noise_points = (data['Cluster_DBSCAN'] == -1).sum()
print(f"Number of noise points: {num_noise_points}")
plt.figure(figsize=(10, 6))
sns.scatterplot(data=data, x='Number of Medicare Beneficiaries', y='Average Submitted Charge Amount',
 hue='Cluster_DBSCAN', palette='viridis', legend='full')
plt.title('DBSCAN Clustering')
plt.show()

dbscan = DBSCAN(eps=0.5, min_samples=4)
data['Cluster_DBSCAN'] = dbscan.fit_predict(data[numeric_columns])
num_noise_points = (data['Cluster_DBSCAN'] == -1).sum()
print(f"Number of noise points: {num_noise_points}")
plt.figure(figsize=(10, 6))
sns.scatterplot(data=data, x='Number of Services', y='Average Medicare Payment Amount',
 hue='Cluster_DBSCAN', palette='viridis', legend='full')
plt.title('DBSCAN Clustering')
plt.show()

#Algoplot of DBScan
eps = 0.5
min_samples = 3
data = data[numeric_columns].dropna()
data = data.sample(n=5000, random_state=42)
fig, axes = plt.subplots(4, 2, figsize=(14, 18))
fig.subplots_adjust(hspace=0.4, wspace=0.4)
axes = axes.flatten()
for i, col in enumerate(numeric_columns):
    # Perform DBSCAN clustering on the current column
    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
    # Reshape data to 2D array for DBSCAN
    data_col = data[[col]].values.reshape(-1, 1)
    data['Cluster'] = dbscan.fit_predict(data_col)
    # Plot the column against its DBSCAN cluster assignments
    ax = axes[i]
    scatter = ax.scatter(data.index, data[col], c=data['Cluster'], cmap='viridis', s=50, alpha=0.5)
    ax.set_title(f'{col} - DBSCAN Clustering')

    cbar = plt.colorbar(scatter, ax=ax)
    cbar.set_label('Cluster')
if i < len(numeric_columns) - 2:
  ax.set_xticklabels([])
for j in range(i + 1, len(axes)):
  fig.delaxes(axes[j])
plt.tight_layout()
plt.show()