# -*- coding: utf-8 -*-
"""eda.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1veJQJupR3ftKRauV3sbsSefNAUmYhXaN

# **IMPORTING DEPENDENCIES**
"""

from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib

df = pd.read_csv("/content/HealthcareProviders.csv")

"""# **BASIC EXPLORATION OF THE DATASET**"""

df.describe(include='all')

"""** ADDING A NEW COLUMN "MONEY DIFFERENCE" IN THE DATASET WHICH CALCULATES THE DIFFERENCE BETWEEN "AVERAGE SUBMITTED CHARGE AMOUNT" COLUMN AND THE "AVERAGE MEDICARE PAYMENT AMOUNT" COLUMN**"""

df["Average Submitted Charge Amount"] = df["Average Submitted Charge Amount"].replace(',', '', regex=True)

df["Average Medicare Payment Amount"] = df["Average Medicare Payment Amount"].replace(',', '', regex=True)

df["Money difference"] = df["Average Submitted Charge Amount"].astype(float) - df["Average Medicare Payment Amount"].astype(float)

"""# **Basic exploration of the dataset with the new column**"""

df.nunique()

(df.isnull().sum()/(len(df)))*100

df.describe(include='all').T

"""**Dropping different irrelevant fields throughout the process**"""

df = df.drop(columns=['index', 'National Provider Identifier','Street Address 1 of the Provider','Street Address 2 of the Provider','Country Code of the Provider'])

df['Last Name/Organization Name of the Provider'] = df['First Name of the Provider'].astype(str) + " " + df['Last Name/Organization Name of the Provider']

df.head()

df=df.drop(columns=['First Name of the Provider'])

df.head()

df.rename(columns = {'Last Name/Organization Name of the Provider':'Full name'}, inplace = True)

df.head()

df=df.drop(columns=['HCPCS Description'])

df.head()

"""### **Finding the mean and standard deviation of the Money difference column and then finding the Z-score of each row **"""

mean = np.mean(df["Money difference"])
std = np.std(df["Money difference"])
print('mean of the dataset is', mean)
print('std. deviation is', std)

threshold = 3
outlier = []
for i in df["Money difference"]:
    z = (i-mean)/std
    if z > threshold:
        outlier.append(i)
print('outlier in dataset is', outlier)

"""## Plotting a distribution graph of the Money Difference column"""

plt.figure(figsize=(16,5))
plt.subplot(1,2,1)
sns.histplot(df['Money difference'], kde=True)

plt.show()

"""### Scaling the numerical fields using the formula of min max scaler"""

column = 'Money difference'
df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())

display(df)

column = 'Average Medicare Payment Amount'
df[column] = (df[column].astype(float) - df[column].astype(float).min()) / (df[column].astype(float).max() - df[column].astype(float).min())

display(df)

column = 'Average Submitted Charge Amount'
df[column] = (df[column].astype(float) - df[column].astype(float).min()) / (df[column].astype(float).max() - df[column].astype(float).min())

display(df)

df.head()

df["Average Medicare Allowed Amount"] = df["Average Medicare Allowed Amount"].replace('.', '', regex=True)
df["Average Medicare Standardized Amount"] = df["Average Medicare Standardized Amount"].replace('.', '', regex=True)

df.drop(columns=['Average Medicare Allowed Amount','Average Medicare Standardized Amount',], inplace=True)

df.head()

mean = np.mean(df["Money difference"])
std = np.std(df["Money difference"])
print('mean of the dataset is', mean)
print('std. deviation is', std)

threshold = 3
outlier = []
for i in df["Money difference"]:
    z = (i-mean)/std
    if z > threshold:
        outlier.append(i)
print('outlier in dataset is', outlier)

"""### Appending a column called Z-score to the dataset to store the Z-score of each row"""

df["Z-score"] = (df["Money difference"] - mean)/std

"""### Making a column called Fraud that represents if we consider the data to be a fraudulent data or not depending on the Z-score. If the Z-score is above 3 then we consider it to be anomalous/fraudulent or if the Z-score is less then we consider it normal."""

df['Fraud'] = df['Z-score'].apply(lambda x: 0 if x <= 3 else 1)

df.head()

df['Fraud'].value_counts()

df.nunique()

df.drop(columns=['Number of Services','Number of Medicare Beneficiaries','Number of Distinct Medicare Beneficiary/Per Day Services','Zip Code of the Provider'], inplace=True)

df.head()

"""### Applying One hot encoding the the columns with few categories"""

df = pd.get_dummies(df, columns=['Gender of the Provider','Entity Type of the Provider','Place of Service','Medicare Participation Indicator','HCPCS Drug Indicator'], dtype='int')

df.head()

df.info()

df.drop(columns=['State Code of the Provider'], inplace=True)

"""### Applying label encoding the fields with large no. of categories"""

from sklearn import preprocessing

label_encoder = preprocessing.LabelEncoder()

df['Provider Type'] = label_encoder.fit_transform(df['Provider Type'])

df.head()

df.drop(columns=['City of the Provider'], inplace=True)

df.head()

df.drop(columns=['Full name','Middle Initial of the Provider','Credentials of the Provider'], inplace=True)

df.head()

df['Fraud'].value_counts()

"""### Dropping the Fraud column to avoid bias in the model while training"""

df.drop(columns=['Fraud'], inplace=True)

df.drop(columns=['HCPCS Code'], inplace=True)

"""### Applying pca to the dataset to find the first two pricipal components"""

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

scaler = StandardScaler()
X_std = scaler.fit_transform(df)

pca = PCA()
X_pca = pca.fit_transform(X_std)

explained_var_ratio = pca.explained_variance_ratio_
cumulative_var_ratio = np.cumsum(explained_var_ratio)

plt.plot(range(1, len(cumulative_var_ratio) + 1), cumulative_var_ratio, marker='o')
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Explained Variance Ratio')
plt.title('Explained Variance Ratio vs. Number of Principal Components')
plt.show()

pca = PCA(n_components=8)

pca.fit(df)

X1=pca.fit_transform(df)
X1

scaler = StandardScaler()
scaled_data = scaler.fit_transform(df)

pca = PCA(n_components=2)
pca_fit = pca.fit(scaled_data)
u = pca.components_.T

pca_component = pd.DataFrame(u,
                             index=df.columns,
                             columns=['PC1', 'PC2']
                            )

print(pca_component)

"""### Plotting the first two Pca components"""

scaler = StandardScaler()
scaled_data = scaler.fit_transform(df)

# Performing PCA
pca = PCA(n_components=2)
pca_transformed = pca.fit_transform(scaled_data)

# Creating a DataFrame for the transformed data
pca_df = pd.DataFrame(pca_transformed, columns=['PC1', 'PC2'])

# Scatter plot of the first two PCA components
plt.figure(figsize=(8, 6))
plt.scatter(pca_df['PC1'], pca_df['PC2'], edgecolor='k', s=50)
plt.title('PCA - First Two Principal Components')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.grid(True)
plt.show()

"""### Using the elbow method to find the optimal no. of clusters in the k-means algorithm"""

X = df.iloc[:, [2, 4]].values

from sklearn.cluster import KMeans
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)

plt.plot(range(1, 11), wcss)
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

"""### Applying K-means algorithm to the data and making a scatter plot to visualize the clusters"""

kmeans = KMeans(n_clusters = 5, init = "k-means++", random_state = 42)
y_kmeans = kmeans.fit_predict(X)

plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 60, c = 'red', label = 'Cluster1')
plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 60, c = 'blue', label = 'Cluster2')
plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 60, c = 'green', label = 'Cluster3')
plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 60, c = 'violet', label = 'Cluster4')
plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 60, c = 'yellow', label = 'Cluster5')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 100, c = 'black', label = 'Centroids')
plt.xlabel('Money difference')
plt.ylabel('Average Medicare Payment Amount')
plt.legend()

plt.show()

"""### Applying Dbscan to the data and making a scatter plot to see the clusters"""

from sklearn.cluster import DBSCAN

db_default = DBSCAN(eps = 0.0375, min_samples = 3).fit(df)
labels = db_default.labels_

colors=['purple','red','blue','green']
plt.figure(figsize=(10,10))
plt.scatter(df["Average Medicare Payment Amount"],df["Money difference"],c=labels,cmap=matplotlib.colors.ListedColormap(colors),s=15)
plt.title('DBSCAN Clustering',fontsize=20)
plt.xlabel('Feature 1',fontsize=14)
plt.ylabel('Feature 2',fontsize=14)
plt.show()

