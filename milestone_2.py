# -*- coding: utf-8 -*-
"""Milestone 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q3Z9laJQ12W2NLBBbIbRg2yG8tVRnqQV

#start hear
"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt
file_path = '/content/drive/MyDrive/Healthcare Providers.csv'
df = pd.read_csv(file_path)

df.isnull().sum()

df.isnull().sum().sum()

"""#Filling the Null values with some values"""

df = df.fillna({'Credentials of the Provider':'NA',
                'Gender of the Provider':'NA'})

"""#Filling the Null values by before values"""

df = df.fillna({'First Name of the Provider' : 'NA'})
df= df.fillna(method = 'pad',axis = 1)
df

df.isnull().sum()

df['Credentials of the Provider'] = df['Credentials of the Provider'].str.replace('.', '', regex=False)
df

# Remove commas from numerical columns
numerical_columns = [
    'Number of Services',
    'Number of Medicare Beneficiaries',
    'Number of Distinct Medicare Beneficiary/Per Day Services',
    'Average Medicare Allowed Amount',
    'Average Submitted Charge Amount',
    'Average Medicare Payment Amount',
    'Average Medicare Standardized Amount'
]

for col in numerical_columns:
    df[col] = df[col].str.replace(',', '').astype(float)

df



"""Here we scaling down the feature

• In the graph above 3 and below 3 values the density is not going to "0"

• In logistic function it is slowly and asintotically get's closer to "0"

#Encoding
"""

from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('/content/drive/MyDrive/Healthcare Providers.csv', encoding='ascii')

# Perform label encoding
label_columns = ['Gender of the Provider', 'Entity Type of the Provider', 'Country Code of the Provider',
                     'HCPCS Drug Indicator', 'Medicare Participation Indicator', 'Place of Service']

label_encoders = {}
def label_encoding(df, columns):
  for col in label_columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le
label_encoding(df,label_columns)

# Perform frequency encoding
freq_columns = ['Provider Type', 'State Code of the Provider', 'Credentials of the Provider', 'HCPCS Code']
def frequency_encoding(df, columns):
    for col in columns:
        freq_enc = df[col].value_counts().to_dict()
        df[col + '_freq'] = df[col].map(freq_enc)
frequency_encoding(df,freq_columns)
df

import pandas as pd


# Define categorical columns
categorical_columns = ['Gender of the Provider', 'Entity Type of the Provider', 'Country Code of the Provider',
                     'HCPCS Drug Indicator', 'Medicare Participation Indicator', 'Place of Service']

# Perform one-hot encoding for categorical columns with high cardinality
high_cardinality_columns = ['Provider Type', 'State Code of the Provider', 'Credentials of the Provider', 'HCPCS Code']
df = pd.get_dummies(df, columns=high_cardinality_columns)

# Perform frequency encoding for categorical columns with low cardinality
low_cardinality_columns = ['Gender of the Provider', 'Entity Type of the Provider', 'Country Code of the Provider',
                     'HCPCS Drug Indicator', 'Medicare Participation Indicator', 'Place of Service']

for col in low_cardinality_columns:
    freq_enc = df[col].value_counts().to_dict()
    df[col + '_freq'] = df[col].map(freq_enc)

# Print the encoded DataFrame
print(df.head())

"""#new columns"""

df['Full Name'] = df['Last Name/Organization Name of the Provider'].fillna('') + ' ' + \
                  df['First Name of the Provider'].fillna('') + ' ' + \
                  df['Middle Initial of the Provider'].fillna('')


df['Full Name'] = df['Full Name'].str.strip()

print(df[['Full Name']].head())

"""By combining the last name,first name and middle name this column has been added."""

numerical_columns = [
    'Number of Services',
    'Number of Medicare Beneficiaries',
    'Number of Distinct Medicare Beneficiary/Per Day Services',
    'Average Medicare Allowed Amount',
    'Average Submitted Charge Amount',
    'Average Medicare Payment Amount',
    'Average Medicare Standardized Amount'
]

for col in numerical_columns:
    df[col] = df[col].str.replace(',', '').astype(float)
df['service_to_beneficiary_ratio'] =  df['Number of Medicare Beneficiaries']/df['Number of Services']

print(df[['service_to_beneficiary_ratio']].head())

"""Through this ratio we can find the  Quality of Care Assessment.

This has be created by dividing the Number of Medicare Beneficiaries and Number of Services they provided.


"""

low_cardinality_columns = ['Gender of the Provider',
    'Country Code of the Provider',
    'Medicare Participation Indicator',
    'Place of Service',
    'Entity Type of the Provider']

for col in low_cardinality_columns:
    freq_enc = df[col].value_counts().to_dict()
    df[col + '_freq'] = df[col].map(freq_enc)

df['Average Submitted Charge Amount'] = pd.to_numeric(df['Average Submitted Charge Amount'], errors='coerce')
df['Average Medicare Payment Amount'] = pd.to_numeric(df['Average Medicare Payment Amount'], errors='coerce')

# Calculate the ratio
df['Charge to Payment Ratio'] = df['Average Submitted Charge Amount'] / df['Average Medicare Payment Amount']


df

"""The "Charge to Payment Ratio column" is created by dividing the 'Average Submitted Charge Amount' by the 'Average Medicare Payment Amount'.

This has been create to the Evaluate Cost Efficiency.
"""

# prompt: pront coliumns

print(df.columns)

"""#Normalization

"""

import numpy as np
import matplotlib.pyplot as plt
def logistic(x):
  return 1.0/(1+np.exp(-x))
x = np.linspace(-6,6,1000)
y = logistic(x)
plt.plot(x,y)
plt.show()

"""Here we scaling down the feature between 0 to 1"""

print(df.columns)

"""• In the above dataset we are having 6
numerical columns and I have just done Normalization for 4 numerical columns.

• Normalization applyed on the Number of Average Medicare Allowed Amount, Average Submitted Charge Amount, Average Medicare Payment Amount, and Average Medicare Standardized Amount.

• Here the maximum value is 1 and the minimum value is 0.

•Insted of using minmax scaller we use Standardization caues in it is very effective to find the outliers than this.

#Standardization

• In Standardization the features will be transformed in such a way that will have the properties of a standard normal distribution.

• mean is usually "0" and the standard deviation is "1".
"""

from sklearn.preprocessing import StandardScaler
import pandas as pd
# Remove commas from numerical columns
numerical_columns = [
    'Number of Services',
    'Number of Medicare Beneficiaries',
    'Number of Distinct Medicare Beneficiary/Per Day Services',
    'Average Medicare Allowed Amount',
    'Average Submitted Charge Amount',
    'Average Medicare Payment Amount',
    'Average Medicare Standardized Amount'
]
for col in numerical_columns:
    if df[col].dtype == 'object':  # Check if the column is of object type (likely string)
        df[col] = df[col].str.replace(',', '').astype(float)
scaler = StandardScaler()

x_scaled = scaler.fit_transform(df[[
       'Average Medicare Allowed Amount', 'Average Submitted Charge Amount',
       'Average Medicare Payment Amount',
       'Average Medicare Standardized Amount']])

print(x_scaled)

#mean value
np.mean(x_scaled)

# varience
np.var(x_scaled)

"""# PCA"""

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

categorical_cols = ['Credentials of the Provider', 'Gender of the Provider', 'Entity Type of the Provider', 'City of the Provider', 'State Code of the Provider', 'Country Code of the Provider', 'Provider Type', 'Medicare Participation Indicator', 'Place of Service', 'HCPCS Drug Indicator']
numerical_cols = ['Number of Services', 'Number of Medicare Beneficiaries', 'Average Medicare Allowed Amount', 'Average Submitted Charge Amount', 'Average Medicare Payment Amount', 'Average Medicare Standardized Amount']


categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

numerical_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

numerical_columns = [
    'Number of Services',
    'Number of Medicare Beneficiaries',
    'Number of Distinct Medicare Beneficiary/Per Day Services',
    'Average Medicare Allowed Amount',
    'Average Submitted Charge Amount',
    'Average Medicare Payment Amount',
    'Average Medicare Standardized Amount'
]

# Combine numerical and encoded categorical columns
combined_columns = numerical_columns + list(df.filter(like='_freq').columns)

# Apply StandardScaler to combined columns
scaler = StandardScaler()
x_scaled = scaler.fit_transform(df[combined_columns])

# Print the scaled data
print(x_scaled)

# prompt: perform k-measn alogirthm on numericals columns like numerical_cols = ['Number of Services', 'Number of Medicare Beneficiaries', 'Average Medicare Allowed Amount', 'Average Submitted Charge Amount', 'Average Medicare Payment Amount', 'Average Medicare Standardized Amount']

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import seaborn as sns

# Define the number of clusters
num_clusters = 3

# Initialize the KMeans model
kmeans = KMeans(n_clusters=num_clusters, random_state=0)
numerical_columns = [
    'Number of Services',
    'Number of Medicare Beneficiaries',
    'Number of Distinct Medicare Beneficiary/Per Day Services',
    'Average Medicare Allowed Amount',
    'Average Submitted Charge Amount',
    'Average Medicare Payment Amount',
    'Average Medicare Standardized Amount'
]

kmeans.fit(df[numerical_cols])

# Get the cluster labels
labels = kmeans.labels_

# Add the cluster labels to the DataFrame
df['Cluster'] = labels

# Print the cluster centers
print(kmeans.cluster_centers_)

# Visualize the clusters
sns.scatterplot(x='Number of Services', y='Average Medicare Payment Amount', hue='Cluster', data=df)
plt.show()

from sklearn.cluster import KMeans
import numpy as np
from sklearn.impute import SimpleImputer

num_clusters = 3

kmeans = KMeans(n_clusters=num_clusters, random_state=0)

imputer = SimpleImputer(strategy='mean')
x_scaled_imputed = imputer.fit_transform(x_scaled)

kmeans.fit(x_scaled_imputed)

labels = kmeans.labels_

df['Cluster'] = labels

print(kmeans.cluster_centers_)

import matplotlib.pyplot as plt

plt.scatter(x_scaled_imputed[:, 0], x_scaled_imputed[:, 1], c=labels, cmap='viridis')
plt.title('Clusters of Healthcare Providers')
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.show()

# prompt: Optimal K Value is determined using either trial and error ranging from (2 to 5) or techniques like elbow plot.

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Initialize an empty list to store the Within Cluster Sum of Squares (WCSS) values
wcss = []

# Loop through a range of cluster numbers (2 to 5)
for i in range(2, 6):
    # Create a KMeans model with the current cluster number
    kmeans = KMeans(n_clusters=i, random_state=0)

    # Fit the model to the data
    kmeans.fit(x_scaled_imputed)

    # Append the WCSS value to the list
    wcss.append(kmeans.inertia_)

# Plot the WCSS values against the cluster numbers
plt.plot(range(2, 6), wcss)
plt.title('Elbow Plot')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

# Choose the optimal number of clusters based on the elbow plot
optimal_k = 3

# Create a KMeans model with the optimal number of clusters
kmeans = KMeans(n_clusters=optimal_k, random_state=0)

# Fit the model to the data
kmeans.fit(x_scaled_imputed)

# Add the cluster labels to the DataFrame
df['Cluster'] = kmeans.labels_

print(kmeans.cluster_centers_)

# Visualize the clusters
plt.scatter(x_scaled_imputed[:, 0], x_scaled_imputed[:, 1], c=labels, cmap='viridis')
plt.title('Clusters of Healthcare Providers')
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.show()

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Selecting relevant numerical columns for k-means clustering
numerical_columns = [
    'Number of Services',
    'Number of Medicare Beneficiaries',
    'Number of Distinct Medicare Beneficiary/Per Day Services',
    'Average Medicare Allowed Amount',
    'Average Submitted Charge Amount',
    'Average Medicare Payment Amount',
    'Average Medicare Standardized Amount'
]

# Extract the data for these columns from 'df'
data_for_clustering = df[numerical_columns]

# Handle any missing values by filling them with the mean of the column
data_for_clustering.fillna(data_for_clustering.mean(), inplace=True)

# Standardize the data before clustering
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data_for_clustering)

# Perform k-means clustering with a chosen number of clusters, e.g., 3
kmeans = KMeans(n_clusters=3, random_state=42)

# Assign the clusters to the original dataframe 'df'
df['Cluster'] = kmeans.fit_predict(data_scaled)

# Show the number of data points in each cluster
df['Cluster'].value_counts()

!pip install scikit-learn
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

imputer = SimpleImputer(strategy='mean')
x_scaled_imputed = imputer.fit_transform(x_scaled)
pca = PCA()

pca.fit(x_scaled_imputed)
for i in range(len(pca.components_)):
    for j in range(i + 1, len(pca.components_)):
        plt.scatter(x_scaled_imputed[:, i], x_scaled_imputed[:, j], c=labels, cmap='viridis') # Use imputed data for plotting
        plt.xlabel('PC' + str(i + 1))
        plt.ylabel('PC' + str(j + 1))
        plt.title('Clusters of Healthcare Providers')
        plt.show()

